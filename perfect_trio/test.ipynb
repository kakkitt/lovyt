{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv # pip install python-dotenv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 불러오기\n",
    "load_dotenv(r'C:\\Users\\user\\Desktop\\LangChain\\Daily\\all.env') \n",
    "\n",
    "# 환경 변수에 API 키 설정\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "# Langsmith Tracing 설정\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "\n",
    "# Fire Crawl API 설정\n",
    "os.environ['FIRE_API_KEY'] = os.getenv('FIRE_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# import document \n",
    "from langchain_community.document_loaders import FireCrawlLoader # pip install langchain-community\n",
    "from langchain_core.documents import Document\n",
    "# from document import Document \n",
    "\n",
    "class DocumentLoader:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def get_docs(self, url: str) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Retrieves documents from the specified URL using the FireCrawlLoader.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to crawl for documents.\n",
    "\n",
    "        Returns:\n",
    "            List[Document]: A list of Document objects containing the retrieved content.\n",
    "        \"\"\"\n",
    "        loader = FireCrawlLoader(\n",
    "            api_key=self.api_key, url=url, mode=\"crawl\"\n",
    "        )\n",
    "\n",
    "        raw_docs = loader.load()\n",
    "        docs = [Document(page_content=doc.page_content, metadata=doc.metadata) for doc in raw_docs]\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saved_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# create vector store\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m store \u001b[38;5;241m=\u001b[39m create_vector_store(\u001b[43msaved_docs\u001b[49m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# creating retriever\u001b[39;00m\n\u001b[0;32m     42\u001b[0m retriever \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'saved_docs' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def create_vector_store(docs, store_path: Optional[str] = None) -> FAISS:\n",
    "    \"\"\"\n",
    "    Creates a FAISS vector store from a list of documents.\n",
    "\n",
    "    Args:\n",
    "        docs (List[Document]): A list of Document objects containing the content to be stored.\n",
    "        store_path (Optional[str]): The path to store the vector store locally. If None, the vector store will not be stored.\n",
    "\n",
    "    Returns:\n",
    "        FAISS: The FAISS vector store containing the documents.\n",
    "    \"\"\"\n",
    "    # Creating text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "    )\n",
    "\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Embedding object\n",
    "    embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "    # Create the FAISS vector store\n",
    "    store = FAISS.from_documents(texts, embedding_model)\n",
    "\n",
    "    # Save the vector store locally if a path is provided\n",
    "    if store_path:\n",
    "        store.save_local(store_path)\n",
    "\n",
    "    return store\n",
    "\n",
    "\n",
    "# create vector store\n",
    "store = create_vector_store(saved_docs)\n",
    "\n",
    "# creating retriever\n",
    "retriever = store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating a retrieval chain for response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def create_generate_chain(llm):\n",
    "    \"\"\"\n",
    "    코드 관련 질문에 답변하기 위한 생성 체인을 만듭니다.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM): 응답 생성에 사용할 언어 모델.\n",
    "\n",
    "    Returns:\n",
    "        컨텍스트와 질문을 입력받아 문자열 응답을 반환하는 호출 가능한 함수.\n",
    "    \"\"\"\n",
    "    generate_template = \"\"\"\n",
    "    You are a helpful code assistant named Speckly. The user provides you with a code-related question whose content is represented by the following context parts (delimited by <context></context>).\n",
    "    Use these to answer the question at the end.\n",
    "    The files deal with Speckle Developer Documentation. You can assume that the user is either a civil engineer, architect, or a software developer.\n",
    "    If you don't know the answer, just say that you don't know. Do NOT try to make up an answer.\n",
    "    If the question is not related to the context, politely respond that you only answer questions related to the context.\n",
    "    Provide as detailed an answer as possible and generate the code in Python (default) unless specifically mentioned by the user in the question.\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    <question>\n",
    "    {input}\n",
    "    </question>\n",
    "    \"\"\"\n",
    "\n",
    "    generate_prompt = PromptTemplate(template=generate_template, input_variables=[\"context\", \"input\"])\n",
    "\n",
    "    # 생성 체인 만들기\n",
    "    generate_chain = generate_prompt | llm | StrOutputParser()\n",
    "\n",
    "    return generate_chain\n",
    "\n",
    "# 생성 체인 만들기\n",
    "generate_chain = create_generate_chain(llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class GraderUtils:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def create_retrieval_grader(self):\n",
    "        \"\"\"\n",
    "        Retrieves documents and evaluates their relevance to the user's question.\n",
    "        \"\"\"\n",
    "        grade_prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "            system\n",
    "            You are a grader assessing relevance of a retrieved document to a user question. If the document contains keywords related to the user question, grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals.\n",
    "            Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "            Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "            \n",
    "            user\n",
    "            Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "            Here is the user question: {input} \\n\n",
    "            \n",
    "            assistant\n",
    "            \"\"\",\n",
    "            input_variables=[\"document\", \"input\"],\n",
    "        )\n",
    "\n",
    "        retriever_grader = grade_prompt | self.model | JsonOutputParser()\n",
    "\n",
    "        return retriever_grader\n",
    "\n",
    "    def create_hallucination_grader(self):\n",
    "        \"\"\"\n",
    "        Assesses whether an answer generated by the LLM is grounded in / supported by a set of facts.\n",
    "        \"\"\"\n",
    "        hallucination_prompt = PromptTemplate(\n",
    "            template=\"\"\"system\n",
    "            You are a grader assessing whether an answer is grounded in / supported by a set of facts. Give a binary score 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "            \n",
    "            user\n",
    "            Here are the facts:\n",
    "            \\n ------- \\n\n",
    "            {documents}\n",
    "            \\n ------- \\n\n",
    "            Here is the answer: {generation}\n",
    "            \n",
    "            assistant\"\"\",\n",
    "            input_variables=[\"generation\", \"documents\"],\n",
    "        )\n",
    "\n",
    "        hallucination_grader = hallucination_prompt | self.model | JsonOutputParser()\n",
    "\n",
    "        return hallucination_grader\n",
    "\n",
    "    def create_code_evaluator(self):\n",
    "        \"\"\"\n",
    "        Evaluates whether the generated code is correct and relevant to the given question.\n",
    "        \"\"\"\n",
    "        eval_template = PromptTemplate(\n",
    "            template=\"\"\"system\n",
    "            You are a code evaluator assessing whether the generated code is correct and relevant to the given question.\n",
    "            Provide a JSON response with the following keys:\n",
    "\n",
    "            'score': A binary score 'yes' or 'no' indicating whether the code is correct and relevant.\n",
    "            'feedback': A brief explanation of your evaluation, including any issues or improvements needed.\n",
    "\n",
    "            user\n",
    "            Here is the generated code:\n",
    "            \\n ------- \\n\n",
    "            {generation}\n",
    "            \\n ------- \\n\n",
    "            Here is the question: {input}\n",
    "            \\n ------- \\n\n",
    "            Here are the relevant documents: {documents}\n",
    "            assistant\"\"\",\n",
    "            input_variables=[\"generation\", \"input\", \"documents\"],\n",
    "        )\n",
    "\n",
    "        code_evaluator = eval_template | self.model | JsonOutputParser()\n",
    "\n",
    "        return code_evaluator\n",
    "\n",
    "    def create_question_rewriter(self):\n",
    "        \"\"\"\n",
    "        Rewrites a given question to improve its clarity and relevance.\n",
    "        \"\"\"\n",
    "        re_write_prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "            system\n",
    "            You are a question rewriter. Your task is to rewrite the given question to make it clearer and more relevant to the context.\n",
    "\n",
    "            user\n",
    "            Here is the original question: {input}\n",
    "\n",
    "            assistant\"\"\",\n",
    "            input_variables=[\"input\"]\n",
    "        )\n",
    "\n",
    "        question_rewriter = re_write_prompt | self.model | StrOutputParser()\n",
    "\n",
    "        return question_rewriter\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Initialize the LLM model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Create an instance of the GraderUtils class\n",
    "grader = GraderUtils(llm)\n",
    "\n",
    "# Get the retrieval grader\n",
    "retrieval_grader = grader.create_retrieval_grader()\n",
    "\n",
    "# Get the hallucination grader\n",
    "hallucination_grader = grader.create_hallucination_grader()\n",
    "\n",
    "# Get the code evaluator\n",
    "code_evaluator = grader.create_code_evaluator()\n",
    "\n",
    "# Get the question rewriter\n",
    "question_rewriter = grader.create_question_rewriter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\user\\\\Desktop\\\\LangChain\\\\Daily\\\\perfect_trio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_21992\\3964852034.py:15: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  with open(\"cralwed_docs\\speckle_docs.pkl\", \"wb\") as f:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: 문서 크롤링 완료\n",
      "Step 1: 문서 로컬에 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pickle\n",
    "\n",
    "# # Step 1: 환경 변수 로드 및 문서 크롤링\n",
    "# load_dotenv(find_dotenv())\n",
    "# from document_loader import DocumentLoader  # 이전에 정의한 DocumentLoader 클래스를 import\n",
    "\n",
    "# Speckle 개발자 문서 크롤링\n",
    "loader = DocumentLoader(api_key=os.getenv('FIRE_API_KEY'))\n",
    "speckle_docs = loader.get_docs(\"https://speckle.guide/dev/server-graphql-api.html#advanced-queries\")\n",
    "print(\"Step 1: 문서 크롤링 완료\")\n",
    "\n",
    "# 문서를 로컬에 저장\n",
    "with open(\"cralwed_docs\\speckle_docs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(speckle_docs, f)\n",
    "print(\"Step 1: 문서 로컬에 저장 완료\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'GraphQL API | Speckle Docs', 'sourceURL': 'https://speckle.guide/dev/server-graphql-api.html#advanced-queries', 'description': 'Documentation on everything Speckle', 'pageStatusCode': 200, 'ogLocaleAlternate': []}, page_content=' [![Speckle Docs](https://speckle.guide/assets/logo-docs.png) Speckle Docs](/)\\n\\n[User Guide](/)\\n\\n[Developer Docs](/dev/)\\n\\n[Automate](/automate/)\\n\\n[3D Viewer](/viewer/)\\n\\n[Speckle Website (opens new window)](https://speckle.systems)\\n\\n[Get Started (opens new window)](https://speckle.systems/getstarted/)\\n\\n[GitHub (opens new window)](https://github.com/specklesystems/speckle-docs/)\\n\\n[User Guide](/)\\n\\n[Developer Docs](/dev/)\\n\\n[Automate](/automate/)\\n\\n[3D Viewer](/viewer/)\\n\\n[Speckle Website (opens new window)](https://speckle.systems)\\n\\n[Get Started (opens new window)](https://speckle.systems/getstarted/)\\n\\n[GitHub (opens new window)](https://github.com/specklesystems/speckle-docs/)\\n\\n*   Developer Docs 👩\\u200d💻\\n    \\n    *   [Introduction](/dev/)\\n        \\n    *   [Architecture](/dev/architecture.html)\\n        \\n    \\n*   Core Concepts\\n    \\n    *   [The Base Object](/dev/base.html)\\n        \\n    *   [Decomposition API](/dev/decomposition.html)\\n        \\n    *   [Kits](/dev/kits.html)\\n        \\n    *   [Transports](/dev/transports.html)\\n        \\n    *   [Apps and Auth](/dev/apps-auth.html)\\n        \\n    \\n*   Advanced Concepts\\n    \\n*   .NET SDK\\n    \\n    *   [Introduction](/dev/dotnet.html)\\n        \\n    *   [Filtering and Flattening Speckle Data in .NET](/dev/FilteringData.html)\\n        \\n    *   [Traversing Structured Data](/dev/traversal.html)\\n        \\n    *   [Objects kit](/dev/objects.html)\\n        \\n    *   [Writing your own connector (Outdated)](/dev/connectors-dev.html)\\n        \\n    *   [Writing your own kit](/dev/kits-dev.html)\\n        \\n    *   [Writing Your Own Transport](/dev/transports-dev.html)\\n        \\n    \\n*   Python SDK\\n    \\n    *   [Introduction](/dev/python.html)\\n        \\n    *   [Examples](/dev/py-examples.html)\\n        \\n    *   [Tutorial: Simple Dashboard](/dev/py-sample.html)\\n        \\n    \\n*   Javascript SDK\\n    \\n    *   [Introduction](/dev/js.html)\\n        \\n    *   [Using our Embeddable 3D Viewer](/dev/viewer.html)\\n        \\n    *   [Using Google Apps Scripts](/dev/js-app-script.html)\\n        \\n    \\n*   Server API & Apps\\n    \\n    *   [Introduction](/dev/server-api.html)\\n        \\n    *   [GraphQL API](/dev/server-graphql-api.html)\\n        *   [GraphQL Explorer](/dev/server-graphql-api.html#graphql-explorer)\\n            *   [Classic GraphQL Explorer](/dev/server-graphql-api.html#classic-graphql-explorer)\\n                \\n            *   [Advanced queries](/dev/server-graphql-api.html#advanced-queries)\\n                \\n    *   [REST API](/dev/server-rest-api.html)\\n        \\n    *   [Stream Preview Images](/dev/server-stream-previews.html)\\n        \\n    *   [Webhooks](/dev/server-webhooks.html)\\n        \\n    *   [Deploying a Server - Kubernetes](/dev/server-setup-k8s.html)\\n        \\n    *   [Deploying a Server - Docker Compose](/dev/server-manualsetup.html)\\n        \\n    *   [Local Development Environment](/dev/server-local-dev.html)\\n        \\n    *   [Database backup, upgrade, and restore](/dev/server-database-migration.html)\\n        \\n    *   [Personal Access Tokens](/dev/tokens.html)\\n        \\n    *   [Creating Your Own App](/dev/apps.html)\\n        \\n    *   [(deprecated) Deploying a Server - DigitalOcean Marketplace App](/dev/server-setup.html)\\n        \\n    \\n\\n[#](#graphql-api)\\n GraphQL API\\n==============================\\n\\nOur Speckle Server offers both a GraphQL API and a [REST API](/dev/server-rest-api)\\n, for most of your queries the GQL API is probably best suited because of its flexibility and ease of use. When working with uploading and downloading objects, the REST API is preferred.\\n\\n[#](#graphql-explorer)\\n GraphQL Explorer\\n----------------------------------------\\n\\nThe best way to explore and understand the Server API is to use our interactive explorer that comes bundled with the server.\\n\\nWARNING\\n\\nAny queries and mutations that you execute through the explorer will use the actual data from the server - take care!\\n\\nSimply head to `CANONICAL_URL/explorer` or to [https://app.speckle.systems/explorer (opens new window)](https://app.speckle.systems/explorer)\\n, and on the right panel you\\'ll be able to see the API docs and schemas. After logging in you\\'ll also be able to execute queries and mutations as the logged in user.\\n\\n![](https://speckle.guide/assets/img/graphql-explorer.b17c15ec.png)\\n\\n### [#](#classic-graphql-explorer)\\n Classic GraphQL Explorer\\n\\nAlternatively, the classic GraphQL explorer is also available at `CANONICAL_URL/graphql` or [https://app.speckle.systems/graphql (opens new window)](https://app.speckle.systems/graphql)\\n.\\n\\n![](https://speckle.guide/assets/img/graphql-explorer-2.2244ce16.png)\\n\\nTo authenticate, you will need to pass in a personal access token in the authorization header:\\n\\n![](https://speckle.guide/assets/img/authorization-header-gql.cd24cbf4.png)\\n\\nTIP\\n\\nHow do you create a token, we hear you ask? Read the section on [personal access tokens](/dev/tokens.html)\\n!\\n\\n### [#](#advanced-queries)\\n Advanced queries\\n\\nOur GQL API also lets you run advanced queries, for instance you can use it to query Revit parameter data. See the examples below.\\n\\n#### [#](#example-1)\\n Example 1\\n\\nWhen trying to query Revit parameters (family, category, etc.) for a specific object (0d0a4...), in a specific stream (c6b0c...) :\\n\\n    query($myQuery:[JSONObject!]){\\n        stream(id:\"c6b0c4077a\"){\\n            object(id:\"0d0a4abc6a5fcc763e6c850dd3d5ecab\"){\\n                totalChildrenCount\\n                children(query: $myQuery select:[\"parameters\", \"speckle_type\", \"type\", \"family\", \"category\"]){\\n                    totalCount\\n                    cursor\\n                    objects{\\n                        id\\n                        data\\n                    }\\n                }\\n            }\\n        }\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n10  \\n11  \\n12  \\n13  \\n14  \\n15  \\n\\nWhere the \"myQuery\" variable is:\\n\\n    {\\n        \"myQuery\": [\\\\\\n            {\\\\\\n                \"field\":\"applicationId\",\\\\\\n                \"value\":\"6cbabf1d-e8d0-47f0-ac4d-9a7923128d37-0006fb07\",\\\\\\n                \"operator\":\"=\"\\\\\\n            }\\\\\\n        ]\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n\\n#### [#](#example-2)\\n Example 2\\n\\nReturn objects while querying by a specific parameter value. Here, only objects with a parameter value greater than 5 are returned.\\n\\n    query($myQuery:[JSONObject!]){\\n        stream(id:\"c6b0c4077a\"){\\n            object(id:\"0d0a4abc6a5fcc763e6c850dd3d5ecab\"){\\n                totalChildrenCount\\n                children(query: $myQuery select:[\"parameters[0]\".value, \"parameters[0].name\"]){\\n                    totalCount\\n                    cursor\\n                    objects{\\n                        id\\n                        data\\n                    }\\n                }\\n            }\\n        }\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n10  \\n11  \\n12  \\n13  \\n14  \\n15  \\n\\nWhere the \"myQuery\" variable is:\\n\\n    {\\n        \"myQuery\": [\\\\\\n            {\\\\\\n                \"field\":\"parameters[0].value\",\\\\\\n                \"value\":5,\\\\\\n                \"operator\":\"<\"\\\\\\n            }\\\\\\n        ]\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n\\n[Edit this page](https://github.com/specklesystems/speckle-docs/edit/main/dev/server-graphql-api.md)\\n (opens new window)\\n\\nLast Updated: 4/3/2024, 8:37:44 PM\\n\\n← [Introduction](/dev/server-api.html) [REST API](/dev/server-rest-api.html)\\n →'),\n",
       " Document(metadata={'title': 'GraphQL API | Speckle Docs', 'sourceURL': 'https://speckle.guide/dev/server-graphql-api.html', 'description': 'Documentation on everything Speckle', 'pageStatusCode': 200, 'ogLocaleAlternate': []}, page_content=' [![Speckle Docs](https://speckle.guide/assets/logo-docs.png) Speckle Docs](/)\\n\\n[User Guide](/)\\n\\n[Developer Docs](/dev/)\\n\\n[Automate](/automate/)\\n\\n[3D Viewer](/viewer/)\\n\\n[Speckle Website (opens new window)](https://speckle.systems)\\n\\n[Get Started (opens new window)](https://speckle.systems/getstarted/)\\n\\n[GitHub (opens new window)](https://github.com/specklesystems/speckle-docs/)\\n\\n[User Guide](/)\\n\\n[Developer Docs](/dev/)\\n\\n[Automate](/automate/)\\n\\n[3D Viewer](/viewer/)\\n\\n[Speckle Website (opens new window)](https://speckle.systems)\\n\\n[Get Started (opens new window)](https://speckle.systems/getstarted/)\\n\\n[GitHub (opens new window)](https://github.com/specklesystems/speckle-docs/)\\n\\n*   Developer Docs 👩\\u200d💻\\n    \\n    *   [Introduction](/dev/)\\n        \\n    *   [Architecture](/dev/architecture.html)\\n        \\n    \\n*   Core Concepts\\n    \\n    *   [The Base Object](/dev/base.html)\\n        \\n    *   [Decomposition API](/dev/decomposition.html)\\n        \\n    *   [Kits](/dev/kits.html)\\n        \\n    *   [Transports](/dev/transports.html)\\n        \\n    *   [Apps and Auth](/dev/apps-auth.html)\\n        \\n    \\n*   Advanced Concepts\\n    \\n*   .NET SDK\\n    \\n    *   [Introduction](/dev/dotnet.html)\\n        \\n    *   [Filtering and Flattening Speckle Data in .NET](/dev/FilteringData.html)\\n        \\n    *   [Traversing Structured Data](/dev/traversal.html)\\n        \\n    *   [Objects kit](/dev/objects.html)\\n        \\n    *   [Writing your own connector (Outdated)](/dev/connectors-dev.html)\\n        \\n    *   [Writing your own kit](/dev/kits-dev.html)\\n        \\n    *   [Writing Your Own Transport](/dev/transports-dev.html)\\n        \\n    \\n*   Python SDK\\n    \\n    *   [Introduction](/dev/python.html)\\n        \\n    *   [Examples](/dev/py-examples.html)\\n        \\n    *   [Tutorial: Simple Dashboard](/dev/py-sample.html)\\n        \\n    \\n*   Javascript SDK\\n    \\n    *   [Introduction](/dev/js.html)\\n        \\n    *   [Using our Embeddable 3D Viewer](/dev/viewer.html)\\n        \\n    *   [Using Google Apps Scripts](/dev/js-app-script.html)\\n        \\n    \\n*   Server API & Apps\\n    \\n    *   [Introduction](/dev/server-api.html)\\n        \\n    *   [GraphQL API](/dev/server-graphql-api.html)\\n        *   [GraphQL Explorer](/dev/server-graphql-api.html#graphql-explorer)\\n            *   [Classic GraphQL Explorer](/dev/server-graphql-api.html#classic-graphql-explorer)\\n                \\n            *   [Advanced queries](/dev/server-graphql-api.html#advanced-queries)\\n                \\n    *   [REST API](/dev/server-rest-api.html)\\n        \\n    *   [Stream Preview Images](/dev/server-stream-previews.html)\\n        \\n    *   [Webhooks](/dev/server-webhooks.html)\\n        \\n    *   [Deploying a Server - Kubernetes](/dev/server-setup-k8s.html)\\n        \\n    *   [Deploying a Server - Docker Compose](/dev/server-manualsetup.html)\\n        \\n    *   [Local Development Environment](/dev/server-local-dev.html)\\n        \\n    *   [Database backup, upgrade, and restore](/dev/server-database-migration.html)\\n        \\n    *   [Personal Access Tokens](/dev/tokens.html)\\n        \\n    *   [Creating Your Own App](/dev/apps.html)\\n        \\n    *   [(deprecated) Deploying a Server - DigitalOcean Marketplace App](/dev/server-setup.html)\\n        \\n    \\n\\n[#](#graphql-api)\\n GraphQL API\\n==============================\\n\\nOur Speckle Server offers both a GraphQL API and a [REST API](/dev/server-rest-api)\\n, for most of your queries the GQL API is probably best suited because of its flexibility and ease of use. When working with uploading and downloading objects, the REST API is preferred.\\n\\n[#](#graphql-explorer)\\n GraphQL Explorer\\n----------------------------------------\\n\\nThe best way to explore and understand the Server API is to use our interactive explorer that comes bundled with the server.\\n\\nWARNING\\n\\nAny queries and mutations that you execute through the explorer will use the actual data from the server - take care!\\n\\nSimply head to `CANONICAL_URL/explorer` or to [https://app.speckle.systems/explorer (opens new window)](https://app.speckle.systems/explorer)\\n, and on the right panel you\\'ll be able to see the API docs and schemas. After logging in you\\'ll also be able to execute queries and mutations as the logged in user.\\n\\n![](https://speckle.guide/assets/img/graphql-explorer.b17c15ec.png)\\n\\n### [#](#classic-graphql-explorer)\\n Classic GraphQL Explorer\\n\\nAlternatively, the classic GraphQL explorer is also available at `CANONICAL_URL/graphql` or [https://app.speckle.systems/graphql (opens new window)](https://app.speckle.systems/graphql)\\n.\\n\\n![](https://speckle.guide/assets/img/graphql-explorer-2.2244ce16.png)\\n\\nTo authenticate, you will need to pass in a personal access token in the authorization header:\\n\\n![](https://speckle.guide/assets/img/authorization-header-gql.cd24cbf4.png)\\n\\nTIP\\n\\nHow do you create a token, we hear you ask? Read the section on [personal access tokens](/dev/tokens.html)\\n!\\n\\n### [#](#advanced-queries)\\n Advanced queries\\n\\nOur GQL API also lets you run advanced queries, for instance you can use it to query Revit parameter data. See the examples below.\\n\\n#### [#](#example-1)\\n Example 1\\n\\nWhen trying to query Revit parameters (family, category, etc.) for a specific object (0d0a4...), in a specific stream (c6b0c...) :\\n\\n    query($myQuery:[JSONObject!]){\\n        stream(id:\"c6b0c4077a\"){\\n            object(id:\"0d0a4abc6a5fcc763e6c850dd3d5ecab\"){\\n                totalChildrenCount\\n                children(query: $myQuery select:[\"parameters\", \"speckle_type\", \"type\", \"family\", \"category\"]){\\n                    totalCount\\n                    cursor\\n                    objects{\\n                        id\\n                        data\\n                    }\\n                }\\n            }\\n        }\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n10  \\n11  \\n12  \\n13  \\n14  \\n15  \\n\\nWhere the \"myQuery\" variable is:\\n\\n    {\\n        \"myQuery\": [\\\\\\n            {\\\\\\n                \"field\":\"applicationId\",\\\\\\n                \"value\":\"6cbabf1d-e8d0-47f0-ac4d-9a7923128d37-0006fb07\",\\\\\\n                \"operator\":\"=\"\\\\\\n            }\\\\\\n        ]\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n\\n#### [#](#example-2)\\n Example 2\\n\\nReturn objects while querying by a specific parameter value. Here, only objects with a parameter value greater than 5 are returned.\\n\\n    query($myQuery:[JSONObject!]){\\n        stream(id:\"c6b0c4077a\"){\\n            object(id:\"0d0a4abc6a5fcc763e6c850dd3d5ecab\"){\\n                totalChildrenCount\\n                children(query: $myQuery select:[\"parameters[0]\".value, \"parameters[0].name\"]){\\n                    totalCount\\n                    cursor\\n                    objects{\\n                        id\\n                        data\\n                    }\\n                }\\n            }\\n        }\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n10  \\n11  \\n12  \\n13  \\n14  \\n15  \\n\\nWhere the \"myQuery\" variable is:\\n\\n    {\\n        \"myQuery\": [\\\\\\n            {\\\\\\n                \"field\":\"parameters[0].value\",\\\\\\n                \"value\":5,\\\\\\n                \"operator\":\"<\"\\\\\\n            }\\\\\\n        ]\\n    }\\n    \\n\\n1  \\n2  \\n3  \\n4  \\n5  \\n6  \\n7  \\n8  \\n9  \\n\\n[Edit this page](https://github.com/specklesystems/speckle-docs/edit/main/dev/server-graphql-api.md)\\n (opens new window)\\n\\nLast Updated: 4/3/2024, 8:37:44 PM\\n\\n← [Introduction](/dev/server-api.html) [REST API](/dev/server-rest-api.html)\\n →')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speckle_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 벡터 스토어 생성\n",
    "\n",
    "\n",
    "store = create_vector_store(speckle_docs)\n",
    "retriever = store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Grader Test: {'score': 'yes'}\n",
      "Hallucination Grader Test: {'score': 'yes'}\n",
      "Code Evaluator Test: {'score': 'yes', 'feedback': \"The generated code is correct and relevant to the given question. The function 'greet' takes a name as input and returns a greeting message, which aligns with the requirements specified in the relevant documents.\"}\n",
      "Question Rewriter Test: How do I use Speckle's Python SDK?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Grader 테스트\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "grader_utils = GraderUtils(llm)\n",
    "\n",
    "# 모든 Grader 테스트\n",
    "retrieval_grader = grader_utils.create_retrieval_grader()\n",
    "document = \"France is a country in Europe. Paris is the capital of France.\"\n",
    "question = \"What is the capital of France?\"\n",
    "\n",
    "# 수정된 호출 방법\n",
    "score = retrieval_grader.invoke({\"document\": document, \"input\": question})\n",
    "print(\"Retrieval Grader Test:\", score)\n",
    "\n",
    "hallucination_grader = grader_utils.create_hallucination_grader()\n",
    "answer = \"The capital of France is Paris.\"\n",
    "facts = [\"France is a country in Europe.\", \"Paris is the capital of France.\"]\n",
    "hallucination_score = hallucination_grader.invoke({\"generation\": answer, \"documents\": facts})\n",
    "print(\"Hallucination Grader Test:\", hallucination_score)\n",
    "\n",
    "code_evaluator = grader_utils.create_code_evaluator()\n",
    "code = \"def greet(name): return f'Hello, {name}!'\"\n",
    "code_question = \"Write a function to greet someone by name.\"\n",
    "documents = [\"A function should take a name as input and return a greeting message.\"]\n",
    "evaluation_result = code_evaluator.invoke({\"generation\": code, \"input\": code_question, \"documents\": documents})\n",
    "print(\"Code Evaluator Test:\", evaluation_result)\n",
    "\n",
    "question_rewriter = grader_utils.create_question_rewriter()\n",
    "original_question = \"how to use speckle's python sdk?\"\n",
    "\n",
    "# 수정된 호출 방법\n",
    "rewritten_question = question_rewriter.invoke({\"input\": original_question})\n",
    "print(\"Question Rewriter Test:\", rewritten_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    그래프의 상태를 나타냅니다.\n",
    "\n",
    "    Attributes:\n",
    "        input: 질문 또는 입력\n",
    "        generation: LLM으로부터 생성된 응답\n",
    "        documents: 관련 문서 리스트\n",
    "    \"\"\"\n",
    "    input: str\n",
    "    generation: str\n",
    "    documents: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNodes:\n",
    "    def __init__(self, llm, retriever, retrieval_grader, hallucination_grader, code_evaluator, question_rewriter):\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        self.retrieval_grader = retrieval_grader\n",
    "        self.hallucination_grader = hallucination_grader\n",
    "        self.code_evaluator = code_evaluator\n",
    "        self.question_rewriter = question_rewriter\n",
    "        self.generate_chain = create_generate_chain(llm)\n",
    "\n",
    "    def retrieve(self, state):\n",
    "        print('---RETRIEVE---')\n",
    "        question = state['input']\n",
    "        documents = self.retriever.retrieve(question)\n",
    "        return {'documents': documents ,'input': question}\n",
    "    \n",
    "    def generate(self, state):\n",
    "        print(\"---GENERATE---\")\n",
    "        question = state[\"input\"]\n",
    "        documents = state[\"documents\"]\n",
    "        generation = self.generate_chain.invoke({\"context\": documents, \"input\": question})\n",
    "        return {\"documents\": documents, \"input\": question, \"generation\": generation}\n",
    "\n",
    "    def grade_documents(self, state):\n",
    "        print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "        question = state[\"input\"]\n",
    "        documents = state[\"documents\"]\n",
    "        filtered_docs = []\n",
    "\n",
    "        for d in documents:\n",
    "            score = self.retrieval_grader.invoke({\"input\": question, \"document\": d.page_content})\n",
    "            if score[\"score\"] == \"yes\":\n",
    "                print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                print(\"---GRADE: DOCUMENT IR-RELEVANT---\")\n",
    "                continue\n",
    "\n",
    "        return {\"documents\": filtered_docs, \"input\": question}\n",
    "\n",
    "    def transform_query(self, state):\n",
    "        print(\"---TRANSFORM QUERY---\")\n",
    "        question = state[\"input\"]\n",
    "        better_question = self.question_rewriter.invoke({\"input\": question})\n",
    "        return {\"documents\": state[\"documents\"], \"input\": better_question}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeGraph:\n",
    "    def __init__(self, hallucination_grader, code_evaluator):\n",
    "        self.hallucination_grader = hallucination_grader\n",
    "        self.code_evaluator = code_evaluator\n",
    "\n",
    "    def decide_to_generate(self, state):\n",
    "        print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "        filtered_documents = state[\"documents\"]\n",
    "\n",
    "        if not filtered_documents:\n",
    "            print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\")\n",
    "            return \"transform_query\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATE---\")\n",
    "            return \"generate\"\n",
    "\n",
    "    def grade_generation_v_documents_and_question(self, state):\n",
    "        print(\"---CHECK HALLUCINATIONS---\")\n",
    "        documents = state[\"documents\"]\n",
    "        generation = state[\"generation\"]\n",
    "\n",
    "        score = self.hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "        if score[\"score\"] == \"yes\":\n",
    "            print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "            score = self.code_evaluator.invoke({\"input\": state[\"input\"], \"generation\": generation, \"documents\": documents})\n",
    "            if score[\"score\"] == \"yes\":\n",
    "                print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "                return \"useful\"\n",
    "            else:\n",
    "                print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "                return \"not useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATIONS ARE HALLUCINATED, RE-TRY---\")\n",
    "            return \"not supported\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "\n",
    "# 그래프 초기화\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# GraphNodes와 EdgeGraph 인스턴스 생성\n",
    "graph_nodes = GraphNodes(llm, retriever, retrieval_grader, hallucination_grader, code_evaluator, question_rewriter)\n",
    "edge_graph = EdgeGraph(hallucination_grader, code_evaluator)\n",
    "\n",
    "# 노드 정의\n",
    "workflow.add_node(\"retrieve\", graph_nodes.retrieve)\n",
    "workflow.add_node(\"grade_documents\", graph_nodes.grade_documents)\n",
    "workflow.add_node(\"generate\", graph_nodes.generate)\n",
    "workflow.add_node(\"transform_query\", graph_nodes.transform_query)\n",
    "\n",
    "# 그래프 빌드\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    edge_graph.decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    edge_graph.grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 그래프 컴파일\n",
    "chain = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Starting a Server using FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "\n",
    "app = FastAPI(\n",
    "    title=\"Speckle Server\",\n",
    "    version=\"1.0\",\n",
    "    description=\"An API server to answer questions regarding the Speckle Developer Docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/\")\n",
    "async def redirect_root_to_docs():\n",
    "    return RedirectResponse(\"/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic.v1 import BaseModel, Field\n",
    "\n",
    "class Input(BaseModel):\n",
    "    input: str\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langserve \n",
    "from langserve import add_routes\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "\n",
    "add_routes(\n",
    "    app,\n",
    "    chain.with_types(input_type=Input, output_type=Output),\n",
    "    path=\"/speckle_chat_3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muvicorn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 기존의 if __name__ == \"__main__\": 블록 안에 있던 코드를 직접 실행\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\LangChain\\Daily\\daily_env\\Lib\\site-packages\\uvicorn\\main.py:577\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    575\u001b[0m         Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m         \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# pragma: full coverage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\LangChain\\Daily\\daily_env\\Lib\\site-packages\\uvicorn\\server.py:65\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# FastAPI 서버 실행 예시 (Jupyter Notebook에서 실행 가능)\n",
    "import uvicorn\n",
    "\n",
    "# 기존의 if __name__ == \"__main__\": 블록 안에 있던 코드를 직접 실행\n",
    "uvicorn.run(app, host=\"localhost\", port=8000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Streamlit/Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
